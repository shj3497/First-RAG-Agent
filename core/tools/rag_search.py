# core/tools/rag_search.py
import openai
import chromadb
import pickle
import os
from typing import Any, List, Dict, Tuple
from openai import AsyncOpenAI
from rank_bm25 import BM25Okapi
from konlpy.tag import Okt  # Mecab ëŒ€ì‹  Oktë¥¼ ì„í¬íŠ¸

from core.tools.base import Tool
# rag_builderì™€ ë™ì¼í•œ ìƒìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ import í•©ë‹ˆë‹¤.
from core.rag_builder import (
    VECTOR_DB_PATH,
    VECTOR_DB_COLLECTION_NAME,
    EMBEDDING_MODEL,
    BM25_INDEX_PATH,  # BM25 ì¸ë±ìŠ¤ ê²½ë¡œ ì¶”ê°€
)

# rag_builderì˜ ì§€ì—° ì´ˆê¸°í™” í—¬í¼ë¥¼ ì§ì ‘ ì¬ì‚¬ìš©í•˜ì§€ ì•Šê¸° ìœ„í•´, ì´ íŒŒì¼ì—ì„œë„ ë…ë¦½ì ìœ¼ë¡œ ì§€ì—° ì´ˆê¸°í™”ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
_openai_client: AsyncOpenAI | None = None


def _get_openai_client() -> AsyncOpenAI:
    """
    OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§€ì—° ìƒì„±í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œì ì— í™˜ê²½ë³€ìˆ˜ê°€ ì—†ì–´ë„ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    """
    global _openai_client
    if _openai_client is None:
        _openai_client = AsyncOpenAI()
    return _openai_client

# OpenAI í´ë¼ì´ì–¸íŠ¸ëŠ” ì§€ì—° ì´ˆê¸°í™”í•©ë‹ˆë‹¤.


class RagSearchTool(Tool):
    """
    í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(ë²¡í„° + í‚¤ì›Œë“œ)ì„ ìˆ˜í–‰í•˜ì—¬ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ì¡°ê°(ì²­í¬)ì„ ì°¾ì•„ ë°˜í™˜í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    """

    def __init__(self):
        # 1. ë²¡í„° DB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
        self._collection = self._client.get_collection(
            name=VECTOR_DB_COLLECTION_NAME)

        # 2. Okt í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
        self._okt = Okt()
        print("âœ… Okt í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

        # 3. BM25 í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ë¡œë“œ
        if os.path.exists(BM25_INDEX_PATH):
            with open(BM25_INDEX_PATH, "rb") as f:
                bm25_data = pickle.load(f)
            self._bm25_index: BM25Okapi = bm25_data['bm25_index']
            self._bm25_corpus_ids: List[str] = bm25_data['corpus_ids']
            self._bm25_corpus_chunks: List[str] = bm25_data['corpus_chunks']
            print(
                f"âœ… BM25 ì¸ë±ìŠ¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ({len(self._bm25_corpus_chunks)}ê°œ ë¬¸ì„œ)")
        else:
            self._bm25_index = None
            print("âš ï¸ ê²½ê³ : BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    @property
    def name(self) -> str:
        return "hybrid_rag_search_tool"

    @property
    def description(self) -> str:
        return (
            "Megazone Cloud(ë©”ê°€ì¡´í´ë¼ìš°ë“œ)ì˜ ì„œë¹„ìŠ¤, ì œí’ˆ, ì†”ë£¨ì…˜ ë“± ë‚´ë¶€ ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. "
            "ì˜ë¯¸ê°€ ì¤‘ìš”í•œ ì§ˆë¬¸ê³¼ íŠ¹ì • í‚¤ì›Œë“œ(ì˜ˆ: ì œí’ˆëª…, ì—ëŸ¬ì½”ë“œ)ê°€ ì¤‘ìš”í•œ ì§ˆë¬¸ ëª¨ë‘ì— íš¨ê³¼ì ì…ë‹ˆë‹¤."
        )

    async def execute(self, query: str, n_results: int = 5) -> Tuple[str, int]:
        """
        ì£¼ì–´ì§„ ì¿¼ë¦¬ë¡œ ë²¡í„° ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ë™ì‹œì— ìˆ˜í–‰í•˜ê³ ,
        ê²°ê³¼ë¥¼ ìœµí•©(RRF)í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        Returns:
            Tuple[str, int]: (í¬ë§·íŒ…ëœ ìµœì¢… ê²°ê³¼ ë¬¸ìì—´, ìµœì¢… ë¬¸ì„œ ê°œìˆ˜)
        """
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰: '{query}'")

        # 1. ë²¡í„° ê²€ìƒ‰ê³¼ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        # í›„ë³´êµ°ì„ ë” ë§ì´ í™•ë³´
        vector_results = await self._vector_search(query, n_results * 2)
        keyword_results = self._keyword_search(query, n_results * 2)

        # --- ìƒì„¸ ë¡œê·¸ ì¶”ê°€ ---
        print(f"  - â¡ï¸  ë²¡í„° ê²€ìƒ‰ ê²°ê³¼: {len(vector_results)}ê°œ")
        if vector_results:
            print(
                f"    - Top vector result: ID={vector_results[0][0]}, Score={vector_results[0][1]:.4f}")

        print(f"  - â¡ï¸  í‚¤ì›Œë“œ ê²€ìƒ‰(BM25) ê²°ê³¼: {len(keyword_results)}ê°œ")
        if keyword_results:
            print(
                f"    - Top keyword result: ID={keyword_results[0][0]}, Score={keyword_results[0][1]:.4f}")
        # --- ë¡œê·¸ ì¶”ê°€ ë ---

        # 2. ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ RRF(Reciprocal Rank Fusion)ë¡œ ìœµí•©
        fused_results = self._reciprocal_rank_fusion(
            [vector_results, keyword_results])

        # --- ìƒì„¸ ë¡œê·¸ ì¶”ê°€ ---
        print(f"  - ìœµí•©(RRF) í›„ ìµœì¢… í›„ë³´: {len(fused_results)}ê°œ")
        if fused_results:
            print(
                f"    - Top fused result: ID={fused_results[0][0]}, Score={fused_results[0][1]:.4f}")
        # --- ë¡œê·¸ ì¶”ê°€ ë ---

        # 3. ìœµí•©ëœ ê²°ê³¼ì—ì„œ ìµœì¢… n_results ê°œìˆ˜ë§Œí¼ ì„ íƒ
        # RRF ê²°ê³¼ëŠ” (doc_id, score) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ, doc_idë§Œ ì¶”ì¶œ
        final_doc_ids = [doc_id for doc_id, _ in fused_results[:n_results]]

        # 4. ìµœì¢… ID ëª©ë¡ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ì •ë³´(ë©”íƒ€ë°ì´í„°)ë¥¼ DBì—ì„œ ê°€ì ¸ì˜´
        if not final_doc_ids:
            return f"'{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", 0

        final_documents = self._collection.get(
            ids=final_doc_ids, include=["metadatas"])

        # 5. ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì´ ì´í•´í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…
        formatted_string = self._format_results(final_documents, query)

        return formatted_string, len(final_doc_ids)

    def _reciprocal_rank_fusion(self, result_sets: List[List[Tuple[str, float]]], k: int = 60) -> List[Tuple[str, float]]:
        """
        ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ ëª©ë¡ì„ RRF ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìœµí•©í•˜ì—¬ ì¬ìˆœìœ„í™”í•©ë‹ˆë‹¤.
        k: ìˆœìœ„ ê°€ì¤‘ì¹˜ ê³„ì‚°ì— ì‚¬ìš©ë˜ëŠ” ìƒìˆ˜.
        """
        scores: Dict[str, float] = {}
        for results in result_sets:
            for rank, (doc_id, _) in enumerate(results, 1):
                if doc_id not in scores:
                    scores[doc_id] = 0.0
                scores[doc_id] += 1.0 / (k + rank)

        # ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ (doc_id, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return sorted(scores.items(), key=lambda item: item[1], reverse=True)

    async def _vector_search(self, query: str, n_results: int) -> List[Tuple[str, float]]:
        """ë²¡í„° DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  (doc_id, score) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not query:
            return []
        query_embedding = await self._embed_query(query)
        results = self._collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            include=["distances"]
        )
        # ChromaDBì˜ distanceëŠ” 'ìœ ì‚¬í•˜ì§€ ì•Šì€ ì •ë„'ì´ë¯€ë¡œ, 1ì—ì„œ ë¹¼ì„œ ì ìˆ˜ë¡œ ë³€í™˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        return list(zip(results['ids'][0], [1 - dist for dist in results['distances'][0]]))

    def _keyword_search(self, query: str, n_results: int) -> List[Tuple[str, float]]:
        """BM25 ì¸ë±ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  (doc_id, score) ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if self._bm25_index is None:
            return []

        # --- ì¿¼ë¦¬ í† í°í™” ë°©ì‹ ë³€ê²½ ---
        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ë„ Oktë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì¼í•˜ê²Œ ëª…ì‚¬ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        tokenized_query = self._okt.nouns(query)
        doc_scores = self._bm25_index.get_scores(tokenized_query)

        # ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ n_resultsê°œ ë§Œí¼ ê°€ì ¸ì˜´
        top_n_indices = sorted(
            range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:n_results]

        # (doc_id, score) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return [(self._bm25_corpus_ids[i], doc_scores[i]) for i in top_n_indices]

    async def _embed_query(self, query: str) -> List[float]:
        """ì¿¼ë¦¬ ë¬¸ìì—´ì„ OpenAI APIë¥¼ í†µí•´ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        response = await _get_openai_client().embeddings.create(
            input=[query],
            model=EMBEDDING_MODEL
        )
        return response.data[0].embedding

    def _format_results(self, final_documents: Dict[str, Any], original_query: str) -> str:
        """ChromaDB ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìµœì¢… ë‹µë³€ì˜ ê·¼ê±° ìë£Œë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ê²Œ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤."""
        if not final_documents or not final_documents.get('ids'):
            return f"'{original_query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        formatted_string = f"--- '{original_query}'ì— ëŒ€í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê²°ê³¼ ---\n\n"

        for i, (doc_id, metadata) in enumerate(zip(final_documents['ids'], final_documents['metadatas'])):
            source_url = metadata.get('page_url', 'ì¶œì²˜ ë¶ˆëª…')
            chunk_text = metadata.get('chunk_text', 'ë‚´ìš© ì—†ìŒ')

            formatted_string += f"ë¬¸ì„œ #{i+1} (ID: {doc_id}):\n"
            formatted_string += f"  - ì¶œì²˜ URL: {source_url}\n"
            formatted_string += f"  - ë‚´ìš©:\n\"\"\"\n{chunk_text}\n\"\"\"\n\n"

        return formatted_string

    # to_openai_format í•¨ìˆ˜ëŠ” nameê³¼ descriptionë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤.
    def to_openai_format(self) -> Dict[str, Any]:
        """
        ì´ ë„êµ¬ë¥¼ OpenAIì˜ Tool Calling ëª…ì„¸ì— ë§ê²Œ JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        LLMì—ê²Œ 'query'ë¼ëŠ” ì´ë¦„ì˜ ë¬¸ìì—´ íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•˜ë‹¤ê³  ì•Œë ¤ì¤ë‹ˆë‹¤.
        """
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•  ì‚¬ìš©ì ì§ˆë¬¸ ë˜ëŠ” ê²€ìƒ‰ì–´",
                        }
                    },
                    "required": ["query"],
                },
            },
        }


# ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œë¥¼ ìœ„í•œ ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì½”ë“œ (ì˜ˆì‹œ)
if __name__ == '__main__':
    import asyncio

    async def main():
        rag_tool = RagSearchTool()
        test_query = "ë©”ê°€ì¡´í´ë¼ìš°ë“œì˜ AI ë°ì´í„° ì†”ë£¨ì…˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
        search_result, count = await rag_tool.execute(query=test_query)
        print(search_result)
        print(f"ìµœì¢… ë¬¸ì„œ ê°œìˆ˜: {count}")

    asyncio.run(main())
