# core/tool_calling_agent.py
# -*- coding: utf-8 -*-
import json
from typing import List

from core.history import get_history_store
from core.base_agent import AVAILABLE_TOOLS, AGENT_MODEL, get_openai_client


async def run_tool_calling_agent(user_query: str, session_id: str = None) -> str:
    """
    OpenAIì˜ Tool Calling ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸ ë¡œì§ì…ë‹ˆë‹¤.
    LLMì´ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì—¬ RAG ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.
    """
    print(
        f"ğŸ¤– (Tool Calling Agent) ì‹¤í–‰ ì‹œì‘ (ì„¸ì…˜ ID: {session_id}, ì§ˆë¬¸: '{user_query}')")

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ìë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    history = get_history_store()

    # --- 1. ë©”ì‹œì§€ ëª©ë¡ êµ¬ì„± ---
    system_prompt = {"role": "system",
                     "content": "You are a helpful assistant that can use tools to answer questions."}

    if session_id:
        past_messages = history.get_messages(session_id)
    else:
        past_messages = []

    user_message = {"role": "user", "content": user_query}
    messages = [system_prompt] + past_messages + [user_message]
    new_messages_for_history = [user_message]

    # --- 2. 1ì°¨ LLM í˜¸ì¶œ: ë„êµ¬ ì‚¬ìš© ê²°ì • ---
    tools_for_openai = [tool.to_openai_format() for tool in AVAILABLE_TOOLS]

    print("ğŸ§  1ì°¨ í˜¸ì¶œ: LLMì—ê²Œ ë„êµ¬ ì„ íƒ ìš”ì²­...")
    first_response = await get_openai_client().chat.completions.create(
        model=AGENT_MODEL,
        messages=messages,
        tools=tools_for_openai,
        tool_choice="auto",
        temperature=0,
    )

    response_message = first_response.choices[0].message
    tool_calls = response_message.tool_calls
    new_messages_for_history.append(
        response_message.model_dump(exclude_unset=True))

    # --- 3. LLMì˜ ì‘ë‹µ ë¶„ì„ ë° ë„êµ¬ ì‹¤í–‰ ---
    if tool_calls:
        print(f"âœ… LLMì´ ë„êµ¬ ì‚¬ìš© ê²°ì •: {len(tool_calls)}ê°œ")
        tool_call = tool_calls[0]
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments)

        tool_to_use = next(
            (tool for tool in AVAILABLE_TOOLS if tool.name == tool_name), None)

        if not tool_to_use:
            return f"ì˜¤ë¥˜: LLMì´ ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ '{tool_name}'ì„ í˜¸ì¶œí–ˆìŠµë‹ˆë‹¤."

        print(f"ğŸƒ ë„êµ¬ ì‹¤í–‰: {tool_name}({tool_args})")
        tool_output = await tool_to_use.execute(**tool_args)

        # --- 4. 2ì°¨ LLM í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ---
        tool_message = {
            "tool_call_id": tool_call.id,
            "role": "tool",
            "name": tool_name,
            "content": tool_output,
        }
        new_messages_for_history.append(tool_message)

        messages_for_second_call = messages + \
            [response_message.model_dump(exclude_unset=True), tool_message]

        print("ğŸ§  2ì°¨ í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ìš”ì²­...")
        second_response = await get_openai_client().chat.completions.create(
            model=AGENT_MODEL,
            messages=messages_for_second_call,
            temperature=0,
        )
        final_answer = second_response.choices[0].message.content
        final_message = second_response.choices[0].message.model_dump(
            exclude_unset=True)
        new_messages_for_history.append(final_message)
        print("âœ… ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")

    else:
        # --- 5. ë„êµ¬ ë¯¸ì‚¬ìš© ì‹œ ---
        print("âœ… LLMì´ ë„êµ¬ ì—†ì´ ì§ì ‘ ë‹µë³€ ê²°ì •")
        final_answer = response_message.content

    # --- 6. ëŒ€í™” ê¸°ë¡ ì €ì¥ ---
    if session_id:
        history.add_messages(session_id, new_messages_for_history)
        print(
            f"ğŸ’¾ ì„¸ì…˜ '{session_id}'ì— ëŒ€í™” ê¸°ë¡ {len(new_messages_for_history)}ê°œ ì €ì¥ ì™„ë£Œ")

    return final_answer
