# core/agent.py
import openai
import json
from typing import List
from openai import AsyncOpenAI

from core.tools.base import Tool
from core.tools.rag_search import RagSearchTool
from core.history import get_history_store  # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ëª¨ë“ˆ import

# --- ì—ì´ì „íŠ¸ ì„¤ì • ---
# ì´ ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë„êµ¬ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
# ì§€ê¸ˆì€ RagSearchTool í•˜ë‚˜ë§Œ ìˆì§€ë§Œ, ë‚˜ì¤‘ì— ë‹¤ë¥¸ ë„êµ¬ë“¤ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
AVAILABLE_TOOLS: List[Tool] = [
    RagSearchTool(),
]

# ì‚¬ìš©í•  OpenAI ëª¨ë¸ì„ ì§€ì •í•©ë‹ˆë‹¤. Tool Callingì„ ì§€ì›í•˜ëŠ” ìµœì‹  ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
AGENT_MODEL = "gpt-4-turbo"

# OpenAI ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ëŠ” ì§€ì—° ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
_openai_client: AsyncOpenAI | None = None


def _get_openai_client() -> AsyncOpenAI:
    global _openai_client
    if _openai_client is None:
        _openai_client = AsyncOpenAI()
    return _openai_client


async def run_agent(user_query: str, session_id: str = None) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ AI ì—ì´ì „íŠ¸ì˜ ì „ì²´ ë¡œì§ì„ ì‹¤í–‰í•˜ê³  ìµœì¢… ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    ëŒ€í™” ê¸°ë¡ì´ ìˆëŠ” ê²½ìš°(session_id ì œê³µ ì‹œ) ì´ë¥¼ í¬í•¨í•˜ì—¬ ë§¥ë½ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    OpenAIì˜ Tool Calling ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ¤– ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ (ì„¸ì…˜ ID: {session_id}, ì§ˆë¬¸: '{user_query}')")

    # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ìë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    history = get_history_store()

    # --- 1. ë©”ì‹œì§€ ëª©ë¡ êµ¬ì„± ---
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” í•­ìƒ ëŒ€í™”ì˜ ì‹œì‘ì— ìœ„ì¹˜í•©ë‹ˆë‹¤.
    system_prompt = {"role": "system",
                     "content": "You are a helpful assistant that can use tools to answer questions."}

    # ì„¸ì…˜ IDê°€ ìˆì„ ê²½ìš°, ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    if session_id:
        past_messages = history.get_messages(session_id)
    else:
        past_messages = []

    # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    user_message = {"role": "user", "content": user_query}

    # ìµœì¢…ì ìœ¼ë¡œ LLMì—ê²Œ ë³´ë‚¼ ì „ì²´ ë©”ì‹œì§€ ëª©ë¡ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
    # [ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸, ì´ì „ ëŒ€í™”ë“¤, í˜„ì¬ ì§ˆë¬¸]
    messages = [system_prompt] + past_messages + [user_message]

    # ì´ë²ˆ í„´(turn)ì—ì„œ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€í•  ë©”ì‹œì§€ë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    new_messages_for_history = [user_message]

    # --- 2. 1ì°¨ LLM í˜¸ì¶œ: ë„êµ¬ ì‚¬ìš© ê²°ì • ---
    tools_for_openai = [tool.to_openai_format() for tool in AVAILABLE_TOOLS]

    print("ğŸ§  1ì°¨ í˜¸ì¶œ: LLMì—ê²Œ ë„êµ¬ ì„ íƒ ìš”ì²­...")
    first_response = await _get_openai_client().chat.completions.create(
        model=AGENT_MODEL,
        messages=messages,  # ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ í¬í•¨í•˜ì—¬ ì „ë‹¬
        tools=tools_for_openai,
        tool_choice="auto",  # LLMì´ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ìë™ìœ¼ë¡œ ê²°ì •í•˜ë„ë¡ í•©ë‹ˆë‹¤.
        temperature=0,  # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
    )

    response_message = first_response.choices[0].message
    tool_calls = response_message.tool_calls

    # LLMì˜ ì‘ë‹µ(ë„êµ¬ í˜¸ì¶œ ìš”ì²­)ë„ ê¸°ë¡ ëŒ€ìƒì…ë‹ˆë‹¤.
    # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì‘ë‹µ ê°ì²´ë¥¼ ë‚˜ì¤‘ì— ì§ë ¬í™” ê°€ëŠ¥í•œ dict í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.
    new_messages_for_history.append(
        response_message.model_dump(exclude_unset=True))

    # --- 3. LLMì˜ ì‘ë‹µ ë¶„ì„ ë° ë„êµ¬ ì‹¤í–‰ ---
    if tool_calls:
        print(f"âœ… LLMì´ ë„êµ¬ ì‚¬ìš© ê²°ì •: {len(tool_calls)}ê°œ")

        # ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œì„ ì§€ì›í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì²« ë²ˆì§¸ ë„êµ¬ í˜¸ì¶œë§Œ ì²˜ë¦¬í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
        tool_call = tool_calls[0]
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì—ì„œ LLMì´ ì„ íƒí•œ ë„êµ¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        tool_to_use = next(
            (tool for tool in AVAILABLE_TOOLS if tool.name == tool_name), None)

        if not tool_to_use:
            return f"ì˜¤ë¥˜: LLMì´ ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬ '{tool_name}'ì„ í˜¸ì¶œí–ˆìŠµë‹ˆë‹¤."

        # ì„ íƒëœ ë„êµ¬ì˜ execute ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤ì œ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
        print(f"ğŸƒ ë„êµ¬ ì‹¤í–‰: {tool_name}({tool_args})")
        tool_output = await tool_to_use.execute(**tool_args)

        # --- 4. 2ì°¨ LLM í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ---
        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ APIì— ì „ë‹¬í•˜ê¸° ìœ„í•œ ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
        tool_message = {
            "tool_call_id": tool_call.id,
            "role": "tool",
            "name": tool_name,
            "content": tool_output,
        }
        # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë©”ì‹œì§€ë„ ê¸°ë¡ ëŒ€ìƒì…ë‹ˆë‹¤.
        new_messages_for_history.append(tool_message)

        # 2ì°¨ í˜¸ì¶œì„ ìœ„í•´ ì „ì²´ ëŒ€í™” íë¦„ì„ ë‹¤ì‹œ ë§Œë“­ë‹ˆë‹¤.
        messages_for_second_call = messages + \
            [response_message.model_dump(exclude_unset=True), tool_message]

        print("ğŸ§  2ì°¨ í˜¸ì¶œ: ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ìš”ì²­...")
        second_response = await _get_openai_client().chat.completions.create(
            model=AGENT_MODEL,
            messages=messages_for_second_call,
            temperature=0,  # ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •
        )

        final_answer = second_response.choices[0].message.content

        # 2ì°¨ í˜¸ì¶œ ì‘ë‹µ(ìµœì¢… ë‹µë³€) ë©”ì‹œì§€ë„ ê¸°ë¡ ëŒ€ìƒì…ë‹ˆë‹¤.
        final_message = second_response.choices[0].message.model_dump(
            exclude_unset=True)
        new_messages_for_history.append(final_message)

        print("âœ… ìµœì¢… ë‹µë³€ ìƒì„± ì™„ë£Œ")

    else:
        # --- 5. ë„êµ¬ ë¯¸ì‚¬ìš© ì‹œ ---
        #    ì²« ë²ˆì§¸ ì‘ë‹µì— í¬í•¨ëœ ì¼ë°˜ ë‹µë³€ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        print("âœ… LLMì´ ë„êµ¬ ì—†ì´ ì§ì ‘ ë‹µë³€ ê²°ì •")
        final_answer = response_message.content
        # ì´ ê²½ìš° `response_message`ê°€ ìµœì¢… ë‹µë³€ì´ë¯€ë¡œ, ì´ë¯¸ ê¸°ë¡ ëŒ€ìƒì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.

    # --- 6. ëŒ€í™” ê¸°ë¡ ì €ì¥ ---
    # ì„¸ì…˜ IDê°€ ì œê³µëœ ê²½ìš°ì—ë§Œ ì´ë²ˆ í„´ì˜ ëŒ€í™” ë‚´ìš©ì„ ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤.
    if session_id:
        history.add_messages(session_id, new_messages_for_history)
        print(
            f"ğŸ’¾ ì„¸ì…˜ '{session_id}'ì— ëŒ€í™” ê¸°ë¡ {len(new_messages_for_history)}ê°œ ì €ì¥ ì™„ë£Œ")

    return final_answer
